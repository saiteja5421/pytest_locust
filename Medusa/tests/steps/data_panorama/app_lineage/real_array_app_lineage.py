import json
import logging
import pandas as pd
import sqlalchemy
import random
import requests

from lib.dscc.data_panorama.app_lineage.api.app_lineage_api import AppLineageInfo
from lib.dscc.data_panorama.app_lineage.models.app_lineage import ApplicationList
from lib.dscc.data_panorama.app_lineage.models.app_lineage import VolumesDetail

logger = logging.getLogger()


global api_response
global array_response
array_response = []
api_response = []
current_obj = {}


def verify_app_listing_with_details(url, api_header, api_table, db_path):
    """This method verifies the application list with details.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    app_lineage_obj = AppLineageInfo(url, api_header)
    app_lineage_app_list_response = app_lineage_obj.get_applications(r="")
    api_app_lineage_filtered_data = _create_api_app_list(app_lineage_app_list_response)

    # Array Data filteration starts here
    db_name = db_path
    table_name = "app_last_collection"
    engine = sqlalchemy.create_engine("sqlite:///%s" % db_name, execution_options={"sqlite_raw_colnames": True})
    df = pd.read_sql_table(table_name, engine)
    dt2_filtered_df = df[df["devicetype"] == "deviceType2"]
    vol_count = dt2_filtered_df.groupby("appsetid")["appsetid"].count()
    snap_count = dt2_filtered_df.groupby("appsetid")["volumesnapcount"].sum()
    system_id = dt2_filtered_df.groupby("appsetid")["arrayid"].last()
    app_name = dt2_filtered_df.groupby("appsetid")["appname"].last()
    sys_name = dt2_filtered_df.groupby("appsetid")["sysname"].last()

    fields = {
        "appname": app_name,
        "sysname": sys_name,
        "sysid": system_id,
        "volcount": vol_count,
        "snapcount": snap_count,
    }

    arr_app_lineage_df = pd.concat(fields, axis=1)
    arr_app_lineage_json = arr_app_lineage_df.to_json(orient="index")
    arr_app_lineage_filtered_data = json.loads(arr_app_lineage_json)
    logger.info("Fleet API (Array) filtered data: ")
    logger.info(arr_app_lineage_filtered_data)

    assert (
        len(api_app_lineage_filtered_data) == len(arr_app_lineage_filtered_data)
        and api_app_lineage_filtered_data == arr_app_lineage_filtered_data
    ), "Application Data Lineage list and its details mismatch between Array and DO API."


def verify_search_app_listing_with_details(url, api_header, api_table, db_path):
    """This method verifies searching the application list with details.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    app_lineage_obj = AppLineageInfo(url, api_header)
    db_name = db_path
    table_name = "app_last_collection"
    engine = sqlalchemy.create_engine("sqlite:///%s" % db_name, execution_options={"sqlite_raw_colnames": True})
    df = pd.read_sql_table(table_name, engine)
    dt2_filtered_df = df[df["devicetype"] == "deviceType2"]
    unique_list_app = dt2_filtered_df["appname"].unique().tolist()
    unique_list_sys = dt2_filtered_df["sysname"].unique().tolist()
    unique_list = unique_list_app + unique_list_sys
    logger.info(unique_list)

    random_list = random.sample(unique_list, 5)
    logger.info(random_list)
    for i in random_list:
        r = f"sort=name%20asc&filter=(contains(name,%27{i}%27)%20or%20contains(system,%27{i}%27))&offset=0&"
        new_app_lineage_app_list_response = app_lineage_obj.get_applications(r=r)
        logger.info(new_app_lineage_app_list_response)

        api_app_lineage_filtered_data = _create_api_app_list(new_app_lineage_app_list_response)

        final_df = dt2_filtered_df.loc[
            (dt2_filtered_df["appname"].str.contains(i) == True) | (dt2_filtered_df["sysname"].str.contains(i) == True)
        ]

        vol_count = final_df.groupby("appsetid")["appsetid"].count()
        snap_count = final_df.groupby("appsetid")["volumesnapcount"].sum()
        system_id = final_df.groupby("appsetid")["arrayid"].last()
        app_name = final_df.groupby("appsetid")["appname"].last()
        sys_name = final_df.groupby("appsetid")["sysname"].last()

        fields = {
            "appname": app_name,
            "sysname": sys_name,
            "sysid": system_id,
            "volcount": vol_count,
            "snapcount": snap_count,
        }

        arr_app_lineage_df = pd.concat(fields, axis=1)
        arr_app_lineage_json = arr_app_lineage_df.to_json(orient="index")
        arr_app_lineage_filtered_data = json.loads(arr_app_lineage_json)
        logger.info(arr_app_lineage_filtered_data)

        assert (
            arr_app_lineage_filtered_data == api_app_lineage_filtered_data
        ), f"Application Data Lineage Search mismatch: Array: {arr_app_lineage_filtered_data} and API: {api_app_lineage_filtered_data}"


def verify_test_selected_app_listing_details(url, api_header, api_table, db_path):
    """This method verifies details of the selected application.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    app_lineage_obj = AppLineageInfo(url, api_header)
    db_name = db_path
    table_name = "app_last_collection"
    engine = sqlalchemy.create_engine("sqlite:///%s" % db_name, execution_options={"sqlite_raw_colnames": True})
    df = pd.read_sql_table(table_name, engine)
    dt2_filtered_df = df[df["devicetype"] == "deviceType2"]
    expected_app_obj: ApplicationList = app_lineage_obj.get_applications()

    for item in expected_app_obj.items:
        appset_id = item.id
        system_id = item.systemId
        logger.info(f"Application ID : {appset_id} and system ID : {system_id}. Application Name: {item.name}")

        # Get volume list for specific application id - DO API
        api_selected_app_lineage = app_lineage_obj.get_application_volumes_detail(app_id=appset_id, system_id=system_id)
        # logger.info(f"DO API output  : {api_selected_app_lineage}")

        api_app_lineage_filtered_data = _create_api_response(api_selected_app_lineage)

        # Get volume list for specific application id - Fleet API Table
        dt2_selected_app_df = dt2_filtered_df.loc[
            (dt2_filtered_df["appsetid"] == appset_id) & (dt2_filtered_df["arrayid"] == system_id)
        ]
        dt2_selected_app_df1 = dt2_selected_app_df[dt2_selected_app_df["isClone"] == False]
        snap_count = dt2_selected_app_df1.volumesnapcount
        volume_name = dt2_selected_app_df1.volumename
        sys_name = dt2_selected_app_df1.sysname
        fields = {
            "volumename": volume_name,
            "snapcount": snap_count,
            "sysname": sys_name,
        }

        arr_app_lineage_df1 = pd.concat(fields, axis=1)
        arr_app_lineage_df1.set_index(dt2_selected_app_df1["volid"], inplace=True)

        arr_app_lineage_df = arr_app_lineage_df1.fillna(0)
        arr_app_lineage_json = arr_app_lineage_df.to_json(orient="index")
        arr_app_lineage_filtered_data = json.loads(arr_app_lineage_json)
        logger.info(f"Fleet API Table Output  : {arr_app_lineage_filtered_data}")

        assert len(arr_app_lineage_filtered_data) == len(
            api_app_lineage_filtered_data
        ), f"Application Data Lineage count mismatch: Array: {len(arr_app_lineage_filtered_data)} and API: {len(api_app_lineage_filtered_data)}"

        assert (
            arr_app_lineage_filtered_data == api_app_lineage_filtered_data
        ), f"Application Data Lineage Search mismatch: Array: {arr_app_lineage_filtered_data} and API: {api_app_lineage_filtered_data}"


def arr_process_snapshots(vol_name, num_snaps, snap_list, df_clone, df_snap):
    for snap_id in snap_list:
        logger.info(f"Selected snapshot: {snap_id}")
        snap_clone_df = df_clone[df_clone["base_snap_id"] == snap_id]
        logger.info(snap_clone_df)
        snap_name = df_snap[df_snap["snapid"] == snap_id]["snapname"].values[0]
        global current_obj
        current_obj.update({"name": snap_name, "id": snap_id, "numClones": len(snap_clone_df)})
        array_response.append(current_obj)
        current_obj = {}

        if snap_clone_df.empty:
            logger.info("The Dataframe is empty, the chain ends here")
        else:
            logger.info("The DataFrame is not empty.")
            clone_list = snap_clone_df["cloneid"].tolist()
            logger.info(f"Number of clones of this snapshot: {len(clone_list)}")
            arr_process_clones(clone_list, df_snap, df_clone)


def arr_process_clones(clone_list, df_snap, df_clone):
    for cloneid in clone_list:
        logger.info(cloneid)
        filtered_df = df_snap[df_snap["volumeId"] == cloneid]
        clone_name = df_clone[df_clone["cloneid"] == cloneid]["clonename"].values[0]
        global current_obj
        current_obj.update({"name": clone_name, "id": cloneid, "numSnapshots": len(filtered_df)})
        array_response.append(current_obj)
        current_obj = {}
        if filtered_df.empty:
            logger.info("The DataFrame is empty, the chain ends here.")
        else:
            logger.info("The DataFrame is not empty.")
            logger.info(f"Number of snapshots of this clone: {len(filtered_df)}")
            arr_process_snapshots(cloneid, len(filtered_df), filtered_df["snapid"].tolist(), df_clone, df_snap)


def verify_test_app_clone_snapshot_mapping_details(url, api_header, api_table, db_path):
    """This method verifies mapping details of the selected volume to snapshots and clones.
    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    app_lineage_obj = AppLineageInfo(url, api_header)
    engine = sqlalchemy.create_engine("sqlite:///%s" % db_path, execution_options={"sqlite_raw_colnames": True})
    df_app = pd.read_sql_table("app_last_collection", engine)
    df_clone = pd.read_sql_table("clone_last_collection", engine)
    df_snap = pd.read_sql_table("snapshot_last_collection", engine)
    df_vol = pd.read_sql_table("volume_last_collection", engine)
    dt2_filtered_df_app = df_app[df_app["devicetype"] == "deviceType2"]
    unique_app_list = dt2_filtered_df_app["appsetid"].unique().tolist()
    logger.info(unique_app_list)

    random_appset_id = random.choice(unique_app_list)
    system_id = dt2_filtered_df_app.loc[dt2_filtered_df_app["appsetid"] == random_appset_id, "arrayid"].values[0]
    app_name = dt2_filtered_df_app.loc[dt2_filtered_df_app["appsetid"] == random_appset_id, "appname"].values[0]
    logger.info(f"Application ID : {random_appset_id} and system ID : {system_id}. Application name: {app_name}")
    # random_appset_id = "0353236256e208e5ed000000000000000000000003"
    # system_id = "0053236256e208e5ed000000000000000000000001"

    # Get volume list for specific application id - DO API
    api_selected_app_lineage = app_lineage_obj.get_application_volumes_detail(
        system_id=system_id, app_id=random_appset_id
    )
    logger.info(f"DO API output  : {api_selected_app_lineage}")

    items = api_selected_app_lineage.items
    vol_list = [item.id for item in items]
    logger.info(vol_list)
    logger.info(f"This application set has {len(vol_list)} volumes")
    for vol_id in vol_list:
        for current_api_item in api_selected_app_lineage.items:
            global api_response
            if current_api_item.id == vol_id:
                global current_obj
                current_obj.update(
                    {
                        "name": current_api_item.name,
                        "id": current_api_item.id,
                        "numSnapshots": current_api_item.numSnapshots,
                    }
                )
                api_response.append(current_obj)
                current_obj = {}
                break

        logger.info(f"Current Volume :{vol_id}")
        api_snap_obj = get_snapshots_info(url, api_header, system_id, vol_id)
        logger.info(api_snap_obj)
        process_snapshots(url, api_header, system_id, api_snap_obj)
        logger.info(f"Completed chain of snapshots and clones for this volume: {vol_id}")

    logger.info(f"Fleet API Table output  :")
    for vol_id in vol_list:
        logger.info(f"Current Volume :{vol_id}")
        num_snaps = len(df_snap[df_snap["volumeId"] == vol_id])
        vol_name = df_vol[df_vol["id"] == vol_id]["name"].values[0]
        snap_list = df_snap[df_snap["volumeId"] == vol_id]["snapid"].tolist()
        global array_response
        current_obj.update({"name": vol_name, "id": vol_id, "numSnapshots": num_snaps})
        array_response.append(current_obj)
        current_obj = {}
        if num_snaps > 0:
            logger.info(f"The volume {vol_name} has {num_snaps} snapshots")
            arr_process_snapshots(vol_name, num_snaps, snap_list, df_clone, df_snap)
            logger.info(f"Completed chain of snapshots and clones for this volume: {vol_id}")
        else:
            logger.info(f"There is no chain linked to this volume {vol_name}")

    api_response = sorted(api_response, key=lambda x: x.get("id", ""))
    array_response = sorted(array_response, key=lambda x: x.get("id", ""))
    logger.info(api_response)
    logger.info(array_response)
    assert len(api_response) == len(array_response), f"Count mismatch"
    assert array_response == api_response, f"Responses not matching"


def get_snapshots_info(url, api_header, system_id, vol_id):
    # Make a request to the snapshots API and obtain the response
    app_lineage_obj = AppLineageInfo(url, api_header)
    snapshots_data = app_lineage_obj.get_application_snapshots_detail(system_id=system_id, volume_uuid=vol_id)
    logger.info(f"Snapshots retrieved: {snapshots_data}")
    return snapshots_data


def get_clones_info(url, api_header, system_id, snapshot_id):
    # Make a request to the clones API and obtain the response
    app_lineage_obj = AppLineageInfo(url, api_header)
    clones_data = app_lineage_obj.get_application_clones_detail(system_id=system_id, snapshot_id=snapshot_id)
    logger.info(f"Clones retrieved:{clones_data}")
    return clones_data


def process_snapshots(url, api_header, system_id, snapshots_data):
    for snapshot in snapshots_data.items:
        logger.info(f"Selected snapshot: {snapshot}")
        logger.info(f"Number of clones of this snapshot: {snapshot.numClones}")
        global current_obj
        current_obj.update({"name": snapshot.name, "id": snapshot.id, "numClones": snapshot.numClones})
        api_response.append(current_obj)
        current_obj = {}
        if snapshot.numClones > 0:
            # logger.info(snapshot)
            logger.info(f"Snapshot ID: {snapshot.id}")
            clone_info = get_clones_info(url, api_header, system_id=system_id, snapshot_id=snapshot.id)
            if clone_info.count > 0:
                process_clones(url, api_header, system_id, clone_info)
            else:
                logger.info(f"No more clones for this snapshot, the chain ends here.")
        else:
            logger.info(f"No more clones for this snapshot, the chain ends here.")


def process_clones(url, api_header, system_id, clones_data):
    for clone in clones_data.items:
        logger.info(f"Selected clone: {clone}")
        logger.info(f"Number of snapshots of this clone: {clone.numSnapshots}")
        global current_obj
        current_obj.update({"name": clone.name, "id": clone.id, "numSnapshots": clone.numSnapshots})
        api_response.append(current_obj)
        current_obj = {}
        if clone.numSnapshots > 0:
            # print(clone)
            logger.info(f"Clone ID: {clone.id}")
            snapshots_info = get_snapshots_info(url, api_header, system_id=system_id, vol_id=clone.id)
            if snapshots_info.count > 0:
                process_snapshots(url, api_header, system_id, snapshots_info)
            else:
                logger.info(f"No more snapshots for this clone, the chain ends here.")
        else:
            logger.info(f"No more snapshots for this clone, the chain ends here.")


def _create_api_app_list(app_lineage_app_list_response):
    app_lineage_app_list = app_lineage_app_list_response.items
    api_app_lineage_app_list_with_details = []
    api_app_lineage_app_with_details = {}

    for current_application in app_lineage_app_list:
        api_app_lineage_app_with_details.update(
            {
                str(current_application.id): {
                    "appname": current_application.name,
                    "sysname": current_application.system,
                    "sysid": current_application.systemId,
                    "volcount": current_application.numClones + current_application.numVolumes,
                    "snapcount": float(current_application.numSnapshots),
                }
            }
        )
        api_app_lineage_app_list_with_details.append(api_app_lineage_app_with_details)
        api_app_lineage_app_with_details = {}

    api_app_lineage_filtered_data = {}
    for api_app_lineage_app in api_app_lineage_app_list_with_details:
        api_app_lineage_filtered_data.update(api_app_lineage_app)

    logger.info("DO Api filtered app lineage data: ")
    logger.info(api_app_lineage_filtered_data)
    return api_app_lineage_filtered_data


def _create_api_response(api_selected_app_lineage):
    api_app_lineage_app_list_with_details = []
    api_app_lineage_app_with_details = {}
    for api_selected_app in api_selected_app_lineage.items:
        api_app_lineage_app_with_details.update(
            {
                str(api_selected_app.id): {
                    "volumename": api_selected_app.name,
                    "snapcount": float(api_selected_app.numSnapshots),
                    "sysname": api_selected_app.system,
                }
            }
        )
        api_app_lineage_app_list_with_details.append(api_app_lineage_app_with_details)
        api_app_lineage_app_with_details = {}

    api_app_lineage_filtered_data = {}
    for k in api_app_lineage_app_list_with_details:
        api_app_lineage_filtered_data.update(k)

    logger.info(f"DO API Output: {api_app_lineage_filtered_data}")
    return api_app_lineage_filtered_data
