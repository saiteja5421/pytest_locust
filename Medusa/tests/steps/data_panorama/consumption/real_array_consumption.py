import json
import logging
import time

from requests import Response
from lib.common.common import get
from lib.dscc.data_panorama.consumption.api.clones_api import ClonesInfo
from lib.dscc.data_panorama.consumption.api.snapshots_api import SnapshotsInfo
from lib.dscc.data_panorama.consumption.api.volumes_api import VolumesInfo
from tests.e2e.data_panorama.panorama_context_models import PanoramaAPI
from tests.steps.data_panorama.sanity_steps.cook_api_response import APITable
from dateutil.parser import isoparse

# from tests.e2e.data_panorama.test_sanity.test_consumption import logger

logger = logging.getLogger()


def verify_collection_time(url, api_header):
    """This Function gets the collection summary and verifies if the latest collection is less than a day old.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
    """
    path: str = f"{PanoramaAPI.collection_summary}"
    response: Response = get(url, path, headers=api_header.authentication_header)
    assert response.status_code == 200, f"API call failed with {response.status_code}"
    response_dict = json.loads(response.text)
    processed_time = response_dict["items"][0]["processedAt"]
    processed_time_epoch = int(isoparse(processed_time).timestamp())
    current_time = int(time.time())
    elapsed_duration = current_time - processed_time_epoch
    day_epoch = 86400
    assert (
        elapsed_duration < day_epoch
    ), f"Last Collection completed over a day back. Last collection epoch {processed_time_epoch}. Current time epoch {current_time}"


def verify_clone_count(url, api_header, api_table):
    """This function gets the number of clones (dt2) from fleet and from atlaspoc api and compares them.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    clone_obj = ClonesInfo(url, api_header)
    clone_consumption = clone_obj.get_clones_consumption()
    api_num_clone = clone_consumption.numClones
    arr_num_clone = api_table.clone.shape[0]
    assert (
        api_num_clone == arr_num_clone
    ), f"Clone count mismatch. Number of Clone in DSCC {api_num_clone} and  in array {arr_num_clone} "
    logger.info(f"Number of clone in array collection is {arr_num_clone}")
    logger.info(f"Number of clone in api {api_num_clone}")


def verify_snap_count(url, api_header, api_table):
    """This function gets the number of snapshots (dt1 & dt2) from fleet and from atlaspoc api and compares them.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    snapshot_obj = SnapshotsInfo(url, api_header)
    snap_consumption = snapshot_obj.get_snapshot_consumption()
    api_num_snap = snap_consumption.numSnapshots
    arr_num_snap = api_table.snapshot.shape[0]
    assert (
        arr_num_snap == api_num_snap
    ), f"Snapshot count mismatch. Number of Snapshot in DSCC {api_num_snap} and  in array {arr_num_snap} "
    logger.info(f"Number of snapshot in array collection is {arr_num_snap}")
    logger.info(f"Number of snapshot in api {api_num_snap}")


def verify_volume_count(url, api_header, api_table: APITable):
    """This function gets the number of volumes (dt1 & dt2) from fleet and from atlaspoc api and compares them.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    volumes_info = VolumesInfo(url, api_header)
    api_obj = volumes_info.get_volumes_consumption()
    logger.info(json.dumps(api_obj.to_dict(), indent=4))
    array_num_volumes = api_table.volume.shape[0]
    api_num_volumes = api_obj.numVolumes
    logger.info(f"Number of volumes in array are {array_num_volumes}")
    logger.info(f"Number of volumes in api are {api_num_volumes}")
    if array_num_volumes != api_num_volumes:
        activity_trend_url = url + "/" + PanoramaAPI.volumes_activity_trend
        do_api_vol_activity_trend = volumes_info.get_volumes_activity_trend(
            url=activity_trend_url, api_header=api_header, sanity=True, filter=False
        )
        do_volume_list = set()
        for i in do_api_vol_activity_trend.items:
            do_volume_list.add(i.name)
        fleet_volume_list = set(api_table.volume.name.to_list())
        mismatch_volume_list = do_volume_list.symmetric_difference(fleet_volume_list)
        logger.error(f"The Excess Volumes are: {mismatch_volume_list}")

    assert (
        api_num_volumes == array_num_volumes
    ), f"Volume count mismatch. Number of volumes in DSCC {api_num_volumes} and  in array {array_num_volumes} "


def verify_volume_capacity(url, api_header, api_table: APITable):
    """This function gets the consumed and total capacity of volumes (dt1 & dt2) from fleet and from atlaspoc api and compares them.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    volumes_info = VolumesInfo(url, api_header)
    api_obj = volumes_info.get_volumes_consumption()
    logger.info(json.dumps(api_obj.to_dict(), indent=4))
    array_volSize_list = api_table.volume.volsize.to_list()
    array_usedsize_list = api_table.volume.usedsize.tolist()

    array_deviceType_list = api_table.volume.devicetype.tolist()
    array_volsize_total_bytes = 0
    array_usedsize_total_bytes = 0

    for i in range(len(array_deviceType_list)):
        if array_deviceType_list[i] == "deviceType2":
            array_volsize_total_bytes += int(array_volSize_list[i]) * (1024**2)
            array_usedsize_total_bytes += int(array_usedsize_list[i]) * (1024**2)
        else:
            array_volsize_total_bytes += int(array_volSize_list[i])
            array_usedsize_total_bytes += int(array_usedsize_list[i]) * (1024**2)

    api_volsize_bytes = api_obj.totalSizeInBytes
    api_usedsize_bytes = api_obj.utilizedSizeInBytes

    logger.info(f"Capacity of volumes in array is {array_volsize_total_bytes}")
    logger.info(f"Capacity of volumes in api is {api_volsize_bytes}")
    assert (
        array_volsize_total_bytes == api_volsize_bytes
    ), f"Volume capacity mismatch. Capacity of volumes in DSCC {api_volsize_bytes} and  in array {array_volsize_total_bytes} "

    logger.info(f"Used Capacity of Volumes in array is {array_usedsize_total_bytes}")
    logger.info(f"Used Capacity of Volumes in api is {api_usedsize_bytes}")
    logger.info(
        f"The difference between Fleet and DO consumed space for Volumes is {array_usedsize_total_bytes - api_usedsize_bytes} bytes"
    )

    # half_tib_in_bytes = 549755813888
    # logger.info("Checking if the Space Consumed by Volume is approximately same in DO and Fleet")
    # Approximate Value matching is being done with an acceptable variation of 0.5TiB as there is a difference between
    # the Actual Fleet collection timings and the scedv01 data collection timings.
    # Also, there is a documentation bug for the same: GLDO-174
    # assert (
    #     array_usedsize_total_bytes - api_usedsize_bytes < half_tib_in_bytes
    # ), f"Volume Capacity mismatch. Capacity of volumes in DSCC is {api_usedsize_bytes} and in array {array_usedsize_total_bytes}"
    assert (
        array_usedsize_total_bytes == api_usedsize_bytes
    ), f"Volume Capacity mismatch. Capacity of volumes in DSCC is {api_usedsize_bytes} and in array {array_usedsize_total_bytes}"


def verify_clone_consumption_capacity(url, api_header, api_table: APITable):
    """This function gets the consumed and total capacity of clones from fleet and from atlaspoc api and compares them.

    Args:
        url (string): v1alpha1 atlaspoc url
        api_header: header needed to be passed alongwith the URL
        api_table: Database generated by 'invoke_collector.py'
    """
    clone_obj = ClonesInfo(url, api_header)
    clone_consumption = clone_obj.get_clones_consumption()
    api_totalSizeInBytes = clone_consumption.totalSizeInBytes
    api_utilizedSizeInBytes = clone_consumption.utilizedSizeInBytes
    arr_totalSizeInBytes = sum(api_table.clone["clonesizebytes"])
    arr_utilizedSizeInBytes = sum(api_table.clone["compressedusedbytes"])

    assert (
        api_totalSizeInBytes == arr_totalSizeInBytes
    ), f"Clone totalbytes size mismatch. Total size of Clone in DSCC {api_totalSizeInBytes} and in array {arr_totalSizeInBytes} "
    logger.info(f"totalbytes size of clone in array collection is {arr_totalSizeInBytes}")
    logger.info(f"totalbytes size of clone in api {api_totalSizeInBytes}")

    # half_tib_in_bytes = 549755813888
    # logger.info("Checking if the Space Consumed by Clones is approximately same in DO and Fleet")
    # Approximate Value matching is being done with an acceptable variation of 0.5TiB as there is a difference between
    # the Actual Fleet collection timings and the scedv01 data collection timings.
    # Also, there is a documentation bug for the same: GLDO-174

    logger.info(f"utilizedbytes size of clone in array collection is {arr_utilizedSizeInBytes}")
    logger.info(f"utilizedbytes size of clone in api {api_utilizedSizeInBytes}")
    logger.info(
        f"The difference between Fleet and DO consumed space for Clones is {arr_utilizedSizeInBytes - api_utilizedSizeInBytes} bytes"
    )

    # assert (
    #     api_utilizedSizeInBytes - arr_utilizedSizeInBytes < half_tib_in_bytes
    # ), f"Clone utilizedbytes size mismatch. Utilized size of Clone in DSCC {api_utilizedSizeInBytes} and in array {arr_utilizedSizeInBytes} "
    assert (
        api_utilizedSizeInBytes == arr_utilizedSizeInBytes
    ), f"Clone utilizedbytes size mismatch. Utilized size of Clone in DSCC {api_utilizedSizeInBytes} and in array {arr_utilizedSizeInBytes} "
